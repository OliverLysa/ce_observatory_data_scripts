{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea07846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41d2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose of script: To download wind turbine data from BEIS' Renewable Energy Planning Database and Wikipedia and merge them\n",
    "\n",
    "# Import libraries from which to call functions e.g. urllib \n",
    "import urllib.request\n",
    "import traceback\n",
    "import pandas as pd  # library for data analysis\n",
    "import requests  # library to handle requests\n",
    "from bs4 import BeautifulSoup  # library to parse HTML documents\n",
    "import pyproj\n",
    "import traceback\n",
    "from lat_lon_parser import parse\n",
    "import geopy.distance\n",
    "\n",
    "crs_british = pyproj.Proj(init='EPSG:27700')\n",
    "crs_wgs84 = pyproj.Proj(init='EPSG:4326')\n",
    "\n",
    "words_to_ignore = ['offshore', 'wind', 'farm', 'plant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38378ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_commonwords_num(string1, string2, filters):\n",
    "    \"\"\"\n",
    "    :param string1:\n",
    "    :param string2:\n",
    "    :param filters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filters = [x.lower() for x in filters]\n",
    "        list1 = string1.lower().split()\n",
    "        list2 = string2.lower().split()\n",
    "        set2 = set(list2)\n",
    "        f = lambda x: x in set2\n",
    "        return len([x for x in list(filter(f, list1)) if x.lower() not in filters])\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "def convert_uk_grid_to_latlon(row):\n",
    "    \"\"\"\n",
    "    :param x:\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = row['X-coordinate']\n",
    "        y = row['Y-coordinate']\n",
    "        long, lat = pyproj.transform(crs_british, crs_wgs84, x, y)\n",
    "        return (lat, long)\n",
    "    except Exception as e:\n",
    "        return (0, 0)\n",
    "\n",
    "\n",
    "def formatted_string_to_latlon(geo_line):\n",
    "    \"\"\"\n",
    "    :param geo_line:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lat, lon = geo_line.split('/')[1].strip().split()\n",
    "        lat = parse(lat)\n",
    "        lon = parse(lon)\n",
    "        return (lat, lon)\n",
    "    except Exception as e:\n",
    "        return (0, 0)\n",
    "\n",
    "\n",
    "def get_distance(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    :param latlon1:\n",
    "    :param latlon2:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return round(geopy.distance.geodesic(latlon1, latlon2).km, 2)\n",
    "    except Exception as e:\n",
    "        print(\"Exception in get_distance: {}\".format(str(e)))\n",
    "        print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89117c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_REPD_Wind_df():\n",
    "    try:\n",
    "        # Download Renewable Energy Planning Data (REPD) to location of script by default. Location of save can be specified elsewhere\n",
    "        url = 'https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1096108/repd-july-2022-corrected.csv'\n",
    "        urllib.request.urlretrieve(url, './Renewable_Energy_Planning_Data.csv')\n",
    "\n",
    "        # List of fields to retain from the REPD (REPD), with those not listed to be dropped\n",
    "        fields = ['Ref ID', 'Record Last Updated (dd/mm/yyyy)',\n",
    "                  'Operator (or Applicant)',\n",
    "                  'Site Name',\n",
    "                  'Technology Type',\n",
    "                  'Installed Capacity (MWelec)',\n",
    "                  'Turbine Capacity (MW)',\n",
    "                  'No. of Turbines',\n",
    "                  'Height of Turbines (m)',\n",
    "                  'Development Status (short)',\n",
    "                  'Address',\n",
    "                  'County',\n",
    "                  'Region',\n",
    "                  'Country',\n",
    "                  'Post Code',\n",
    "                  'X-coordinate',\n",
    "                  'Y-coordinate',\n",
    "                  'Operational']\n",
    "\n",
    "        # Read in the REPD csv file, specifying the encoding, while keeping only selected fields\n",
    "        REPD = pd.read_csv(r'Renewable_Energy_Planning_Data.csv', encoding='latin1', usecols=fields)\n",
    "\n",
    "        # Clear column headings of spaces and anything after brackets/parenthesis to make calling them easier e.g. in filtering\n",
    "        REPD.columns = REPD.columns.str.replace(' ', '')\n",
    "        REPD.columns = REPD.columns.str.replace(r\"\\(.*\\)\", \"\")\n",
    "\n",
    "        # Filter to offshore wind in the technology type column\n",
    "        filter_list_technology = ['Wind Onshore']\n",
    "        REPD_Wind = REPD[REPD.TechnologyType.isin(filter_list_technology)]\n",
    "\n",
    "        # Filter to operational in the development status column\n",
    "        filter_list_status = ['Operational']\n",
    "        REPD_Wind = REPD_Wind[REPD_Wind.DevelopmentStatus.isin(filter_list_status)]\n",
    "\n",
    "        # Remove leading and trailing spaces to make it easier to match across data tables\n",
    "        REPD_Wind['SiteName'] = REPD_Wind['SiteName'].str.strip()\n",
    "        return REPD_Wind\n",
    "    except Exception as e:\n",
    "        print(\"Exception in get_REPD_Wind_df: {}\".format(str(e)))\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4effe706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in get_REPD_Wind_df: 'DataFrame' object has no attribute 'DevelopmentStatus'\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/vc/gszmszx94qn2yq038bgz88mr0000gn/T/ipykernel_75828/3279753695.py\", line 39, in get_REPD_Wind_df\n",
      "    REPD_Wind = REPD_Wind[REPD_Wind.DevelopmentStatus.isin(filter_list_status)]\n",
      "  File \"/Users/oliverlysaght/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py\", line 6204, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'DataFrame' object has no attribute 'DevelopmentStatus'\n",
      "\n",
      "Exception in main: 'NoneType' object has no attribute 'apply'\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/vc/gszmszx94qn2yq038bgz88mr0000gn/T/ipykernel_75828/1932107905.py\", line 7, in main\n",
      "    REPD_Wind['gov_coords'] = REPD_Wind.apply(lambda row: convert_uk_grid_to_latlon(row), axis=1)\n",
      "AttributeError: 'NoneType' object has no attribute 'apply'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # just extracting the data\n",
    "        Wikipedia = pd.read_excel(r'Total_onshore.xlsx')\n",
    "        REPD_Wind = get_REPD_Wind_df()\n",
    "        # converting cooords to  lat/lon we canuse  to calculate distance\n",
    "        REPD_Wind['gov_coords'] = REPD_Wind.apply(lambda row: convert_uk_grid_to_latlon(row), axis=1)\n",
    "        Wikipedia['wiki_coords'] = Wikipedia['Coordinates'].apply(formatted_string_to_latlon)\n",
    "\n",
    "        Wikipedia.to_csv('Wiki.csv', index=False)\n",
    "        REPD_Wind.to_csv('REPD_Wind.csv')\n",
    "\n",
    "        # Priority 1:exact matchjooin\n",
    "        merged_left = pd.merge(left=REPD_Wind, right=Wikipedia, how='left', left_on='SiteName', right_on='Name')\n",
    "\n",
    "        # splitting the df into 2 dataframes: with 'pair' after  join (matched)and not matched\n",
    "        # we are going tofind pairsfor 'not matched'\n",
    "        matched = merged_left[merged_left['Name'].str.len() > 0]\n",
    "        not_matched = merged_left[merged_left['Name'].isnull()]\n",
    "        # matched['distance'] = matched.apply(lambda x: get_distance(x['gov_coords'], x['wiki_coords']), axis=1)\n",
    "\n",
    "        series_to_join = []\n",
    "        # iterating non-matched df\n",
    "        for repd_index, repd_row in not_matched.iterrows():\n",
    "            min_distance = 100000\n",
    "            matches_distance = 100000\n",
    "            row_detected = None\n",
    "            match = None\n",
    "            for wiki_index, wiki_row in Wikipedia.iterrows():\n",
    "\n",
    "                # calculating distance with each wiki object\n",
    "                distance = get_distance(repd_row['gov_coords'], wiki_row['wiki_coords'])\n",
    "\n",
    "                # checking for 'inner matches'\n",
    "                if repd_row['SiteName'] in wiki_row['Name'] or wiki_row['Name'] in repd_row['SiteName']:\n",
    "                    if distance < matches_distance:\n",
    "                        match = wiki_row\n",
    "\n",
    "                # checling for ''common words\n",
    "                elif find_commonwords_num(repd_row['SiteName'], wiki_row['Name'], words_to_ignore) > 1:\n",
    "                    if distance < matches_distance:\n",
    "                        match = wiki_row\n",
    "                # update values if it's close\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    row_detected = wiki_row\n",
    "            print('*')\n",
    "            print(repd_row['SiteName'])\n",
    "            # let's check if closest objects haveat least onecommon  word\n",
    "            common_words = find_commonwords_num(repd_row['SiteName'], row_detected['Name'], words_to_ignore)\n",
    "            if common_words == 0 and match is not None:\n",
    "                # it not - lt's use aclosest match\n",
    "                print(match['Name'])\n",
    "                row_to_join = match\n",
    "\n",
    "            elif common_words > 0:\n",
    "                print(row_detected['Name'])\n",
    "                row_to_join = row_detected\n",
    "            else:\n",
    "                print('Not found....')\n",
    "                series_to_join.append(repd_row)\n",
    "                continue\n",
    "            # updating values in initial series\n",
    "            for k in row_to_join.keys():\n",
    "                repd_row[k] = row_to_join[k]\n",
    "            series_to_join.append(repd_row)\n",
    "\n",
    "        # jet's join a list to df and join with amatched df\n",
    "        new_matched = pd.DataFrame(series_to_join)\n",
    "        new_matched = matched.append(new_matched)\n",
    "        # filter out some columns\n",
    "        new_matched = new_matched[\n",
    "            [x for x in new_matched.columns if x not in ['Coordinates', 'wiki_coords', 'gov_coords']]]\n",
    "        new_matched.to_csv(\"final_joined.csv\", index=False)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception in main: {}\".format(str(e)))\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
