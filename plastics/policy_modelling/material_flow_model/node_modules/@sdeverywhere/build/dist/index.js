// src/build/build.ts
import { join as joinPath6 } from "path";
import { err as err3, ok as ok3 } from "neverthrow";

// src/config/config-loader.ts
import { existsSync, lstatSync, mkdirSync } from "fs";
import { dirname, isAbsolute, join as joinPath, relative, resolve as resolvePath } from "path";
import { fileURLToPath } from "url";
import { err, ok } from "neverthrow";
async function loadConfig(mode, config, sdeDir, sdeCmdPath) {
  let userConfig;
  if (typeof config === "object") {
    userConfig = config;
  } else {
    let configPath;
    if (typeof config === "string") {
      configPath = config;
    } else {
      configPath = joinPath(process.cwd(), "sde.config.js");
    }
    try {
      if (!existsSync(configPath)) {
        return err(new Error(`Cannot find config file '${configPath}'`));
      }
      const configRelPath = relativeToSourcePath(configPath);
      const configModule = await import(configRelPath);
      userConfig = await configModule.config();
    } catch (e) {
      return err(new Error(`Failed to load config file '${configPath}': ${e.message}`));
    }
  }
  try {
    const resolvedConfig = resolveUserConfig(userConfig, mode, sdeDir, sdeCmdPath);
    return ok({
      userConfig,
      resolvedConfig
    });
  } catch (e) {
    return err(e);
  }
}
function resolveUserConfig(userConfig, mode, sdeDir, sdeCmdPath) {
  function expectDirectory(propName, path) {
    if (!existsSync(path)) {
      throw new Error(`The configured ${propName} (${path}) does not exist`);
    } else if (!lstatSync(path).isDirectory()) {
      throw new Error(`The configured ${propName} (${path}) is not a directory`);
    }
  }
  let rootDir;
  if (userConfig.rootDir) {
    rootDir = resolvePath(userConfig.rootDir);
    expectDirectory("rootDir", rootDir);
  } else {
    rootDir = process.cwd();
  }
  let prepDir;
  if (userConfig.prepDir) {
    prepDir = resolvePath(userConfig.prepDir);
  } else {
    prepDir = resolvePath(rootDir, "sde-prep");
  }
  mkdirSync(prepDir, { recursive: true });
  const userModelFiles = userConfig.modelFiles;
  const modelFiles = [];
  for (const userModelFile of userModelFiles) {
    const modelFile = resolvePath(userModelFile);
    if (!existsSync(modelFile)) {
      throw new Error(`The configured model file (${modelFile}) does not exist`);
    }
    modelFiles.push(modelFile);
  }
  let modelInputPaths;
  if (userConfig.modelInputPaths && userConfig.modelInputPaths.length > 0) {
    modelInputPaths = userConfig.modelInputPaths;
  } else {
    modelInputPaths = modelFiles;
  }
  let watchPaths;
  if (userConfig.watchPaths && userConfig.watchPaths.length > 0) {
    watchPaths = userConfig.watchPaths;
  } else {
    watchPaths = modelFiles;
  }
  const rawGenFormat = userConfig.genFormat || "js";
  let genFormat;
  switch (rawGenFormat) {
    case "js":
      genFormat = "js";
      break;
    case "c":
      genFormat = "c";
      break;
    default:
      throw new Error(`The configured genFormat value is invalid; must be either 'js' or 'c'`);
  }
  let outListingFile;
  if (userConfig.outListingFile) {
    if (isAbsolute(userConfig.outListingFile)) {
      outListingFile = userConfig.outListingFile;
    } else {
      outListingFile = resolvePath(rootDir, userConfig.outListingFile);
    }
  }
  return {
    mode,
    rootDir,
    prepDir,
    modelFiles,
    modelInputPaths,
    watchPaths,
    genFormat,
    outListingFile,
    sdeDir,
    sdeCmdPath
  };
}
function relativeToSourcePath(filePath) {
  const srcDir = dirname(fileURLToPath(import.meta.url));
  const relPath = relative(srcDir, filePath);
  return relPath.replaceAll("\\", "/");
}

// src/_shared/log.ts
import { writeFileSync } from "fs";
import pico from "picocolors";
var activeLevels = /* @__PURE__ */ new Set(["error", "info"]);
var overlayFile;
var overlayEnabled = false;
var overlayHtml = "";
function setActiveLevels(logLevels) {
  activeLevels.clear();
  for (const level of logLevels) {
    activeLevels.add(level);
  }
}
function setOverlayFile(file, enabled) {
  overlayFile = file;
  overlayEnabled = enabled;
  writeFileSync(overlayFile, "");
}
function log(level, msg) {
  if (activeLevels.has(level)) {
    if (level === "error") {
      console.error(pico.red(msg));
      logToOverlay(msg);
    } else {
      console.log(msg);
      logToOverlay(msg);
    }
  }
}
function logError(e) {
  const stack = e.stack || "";
  const stackLines = stack.split("\n").filter((s) => s.match(/^\s+at/));
  const trace = stackLines.slice(0, 3).join("\n");
  console.error(pico.red(`
ERROR: ${e.message}`));
  console.error(pico.dim(pico.red(`${trace}
`)));
  logToOverlay(`
ERROR: ${e.message}`, true);
  logToOverlay(`${trace}
`, true);
}
function writeOverlayFiles() {
  writeFileSync(overlayFile, overlayHtml);
}
function clearOverlay() {
  if (!overlayEnabled) {
    return;
  }
  overlayHtml = "";
  writeOverlayFiles();
}
var indent = "&nbsp;".repeat(4);
function logToOverlay(msg, error = false) {
  if (!overlayEnabled) {
    return;
  }
  if (error) {
    msg = `<span class="overlay-error">${msg}</span>`;
  }
  const msgHtml = msg.replace(/\n/g, "\n<br/>").replace(/\s{2}/g, indent);
  if (overlayHtml) {
    overlayHtml += `<br/>${msgHtml}`;
  } else {
    overlayHtml = `${msgHtml}`;
  }
  writeOverlayFiles();
}

// src/build/impl/build-once.ts
import { existsSync as existsSync3, readFileSync as readFileSync2, writeFileSync as writeFileSync3 } from "fs";
import { writeFile as writeFile2 } from "fs/promises";
import { join as joinPath5 } from "path";
import { err as err2, ok as ok2 } from "neverthrow";

// src/context/spawn-child.ts
import { spawn } from "cross-spawn";
function spawnChild(cwd, command, args, abortSignal, opts) {
  return new Promise((resolve, reject) => {
    if (abortSignal?.aborted) {
      reject(new Error("ABORT"));
      return;
    }
    let childProc;
    const localLog = (s, err4 = false) => {
      if (childProc === void 0) {
        return;
      }
      log(err4 ? "error" : "info", s);
    };
    const abortHandler = () => {
      if (childProc) {
        log("info", "Killing existing build process...");
        childProc.kill("SIGKILL");
        childProc = void 0;
      }
      reject(new Error("ABORT"));
    };
    abortSignal?.addEventListener("abort", abortHandler, { once: true });
    const stdoutMessages = [];
    const stderrMessages = [];
    const logMessage = (msg, err4) => {
      let includeMessage = true;
      if (opts?.ignoredMessageFilter && msg.trim().startsWith(opts.ignoredMessageFilter)) {
        includeMessage = false;
      }
      if (includeMessage) {
        const lines = msg.trim().split("\n");
        for (const line of lines) {
          localLog(`  ${line}`, err4);
        }
      }
    };
    childProc = spawn(command, args, {
      cwd
    });
    childProc.stdout.on("data", (data) => {
      const msg = data.toString();
      if (opts?.captureOutput === true) {
        stdoutMessages.push(msg);
      }
      if (opts?.logOutput !== false) {
        logMessage(msg, false);
      }
    });
    childProc.stderr.on("data", (data) => {
      const msg = data.toString();
      if (opts?.captureOutput === true) {
        stderrMessages.push(msg);
      }
      if (opts?.logOutput !== false) {
        logMessage(msg, true);
      }
    });
    childProc.on("error", (err4) => {
      localLog(`Process error: ${err4}`, true);
    });
    childProc.on("close", (code, signal) => {
      abortSignal?.removeEventListener("abort", abortHandler);
      childProc = void 0;
      if (signal) {
        return;
      }
      const processOutput = {
        exitCode: code,
        stdoutMessages,
        stderrMessages
      };
      if (code === 0) {
        resolve(processOutput);
      } else if (!signal) {
        if (opts?.ignoreError === true) {
          resolve(processOutput);
        } else {
          reject(new Error(`Child process failed (code=${code})`));
        }
      }
    });
  });
}

// src/context/context.ts
var BuildContext = class {
  /**
   * @param config The resolved configuration.
   * @hidden
   */
  constructor(config, stagedFiles, abortSignal) {
    this.config = config;
    this.stagedFiles = stagedFiles;
    this.abortSignal = abortSignal;
  }
  /**
   * Log a message to the console and/or the in-browser overlay panel.
   *
   * @param level The log level (verbose, info, error).
   * @param msg The message.
   */
  log(level, msg) {
    log(level, msg);
  }
  /**
   * Prepare for writing a file to the staged directory.
   *
   * This will add the path to the array of tracked files and will create the
   * staged directory if needed.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file will be written (this must be a relative path).
   * @param srcFile The name of the file as written to the `staged` directory.
   * @param dstDir The absolute path to the destination directory where the staged
   * file will be copied when the build has completed.
   * @param dstFile The name of the file as written to the destination directory.
   * @return The absolute path to the staged file.
   */
  prepareStagedFile(srcDir, srcFile, dstDir, dstFile) {
    return this.stagedFiles.prepareStagedFile(srcDir, srcFile, dstDir, dstFile);
  }
  /**
   * Write a file to the staged directory.
   *
   * This file will be copied (along with other staged files) into the destination
   * directory only after the build process has completed.  Copying all staged files
   * at once helps improve the local development experience by making it so that
   * live reloading tools only need to refresh once instead of every time a build
   * file is written.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file will be written (this must be a relative path).
   * @param dstDir The absolute path to the destination directory where the staged
   * file will be copied when the build has completed.
   * @param filename The name of the file.
   * @param content The file content.
   */
  writeStagedFile(srcDir, dstDir, filename, content) {
    this.stagedFiles.writeStagedFile(srcDir, dstDir, filename, content);
  }
  /**
   * Spawn a child process that runs the given command.
   *
   * @param cwd The directory in which the command will be executed.
   * @param command The command to execute.
   * @param args The arguments to pass to the command.
   * @param opts Additional options to configure the process.
   * @returns The output of the process.
   */
  spawnChild(cwd, command, args, opts) {
    return spawnChild(cwd, command, args, this.abortSignal, opts);
  }
};

// src/context/staged-files.ts
import { copyFileSync, existsSync as existsSync2, mkdirSync as mkdirSync2, readFileSync, statSync, writeFileSync as writeFileSync2 } from "fs";
import { join as joinPath2 } from "path";
var StagedFiles = class {
  constructor(prepDir) {
    this.stagedFiles = [];
    this.baseStagedDir = joinPath2(prepDir, "staged");
  }
  /**
   * Prepare for writing a file to the staged directory.
   *
   * This will add the path to the array of tracked files and will create the
   * staged directory if needed.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file will be written (this must be a relative path).
   * @param srcFile The name of the file as written to the `staged` directory.
   * @param dstDir The absolute path to the destination directory where the staged
   * file will be copied when the build has completed.
   * @param dstFile The name of the file as written to the destination directory.
   * @return The absolute path to the staged file.
   */
  prepareStagedFile(srcDir, srcFile, dstDir, dstFile) {
    const stagedFile = {
      srcDir,
      srcFile,
      dstDir,
      dstFile
    };
    if (this.stagedFiles.indexOf(stagedFile) < 0) {
      this.stagedFiles.push(stagedFile);
    }
    const stagedDir = joinPath2(this.baseStagedDir, srcDir);
    if (!existsSync2(stagedDir)) {
      mkdirSync2(stagedDir, { recursive: true });
    }
    return joinPath2(stagedDir, srcFile);
  }
  /**
   * Write a file to the staged directory.
   *
   * This file will be copied (along with other staged files) into the destination
   * directory only after the build process has completed.  Copying all staged files
   * at once helps improve the local development experience by making it so that
   * live reloading tools only need to refresh once instead of every time a build
   * file is written.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file will be written (this must be a relative path).
   * @param dstDir The absolute path to the destination directory where the staged
   * file will be copied when the build has completed.
   * @param filename The name of the file.
   * @param content The file content.
   */
  writeStagedFile(srcDir, dstDir, filename, content) {
    const stagedFilePath = this.prepareStagedFile(srcDir, filename, dstDir, filename);
    writeFileSync2(stagedFilePath, content);
  }
  /**
   * Return the absolute path to the staged file for the given source directory and file name.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file would be written initially (this must be a relative path).
   * @param srcFile The name of the file.
   */
  getStagedFilePath(srcDir, srcFile) {
    return joinPath2(this.baseStagedDir, srcDir, srcFile);
  }
  /**
   * Return true if the staged file exists for the given source directory and file name.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file would be written initially (this must be a relative path).
   * @param srcFile The name of the file.
   */
  stagedFileExists(srcDir, srcFile) {
    const fullSrcPath = this.getStagedFilePath(srcDir, srcFile);
    return existsSync2(fullSrcPath);
  }
  /**
   * Return true if the destination file exists for the given source directory and file name.
   *
   * @param srcDir The directory underneath the configured `staged` directory where
   * the file would be written initially (this must be a relative path).
   * @param srcFile The name of the file.
   */
  destinationFileExists(srcDir, srcFile) {
    const f = this.stagedFiles.find((f2) => f2.srcDir === srcDir && f2.srcFile === srcFile);
    if (f === void 0) {
      return false;
    }
    const fullDstPath = joinPath2(f.dstDir, f.dstFile);
    return existsSync2(fullDstPath);
  }
  /**
   * Copy staged files to their destination; this will only copy the staged
   * files if they are different than the existing destination files.  We
   * copy the files in a batch like this so that hot module reload is only
   * triggered once at the end of the whole build process.
   */
  copyChangedFiles() {
    log("info", "Copying changed files into place...");
    for (const f of this.stagedFiles) {
      this.copyStagedFile(f);
    }
    log("info", "Done copying files");
  }
  /**
   * Copy a file from the `staged` directory to its destination.  If the file already
   * exists in the destination directory and has the same contents as the source file,
   * the file will not be copied and this function will return false.
   *
   * @param f The staged file entry.
   */
  copyStagedFile(f) {
    if (!existsSync2(f.dstDir)) {
      mkdirSync2(f.dstDir, { recursive: true });
    }
    const fullSrcPath = this.getStagedFilePath(f.srcDir, f.srcFile);
    const fullDstPath = joinPath2(f.dstDir, f.dstFile);
    const needsCopy = filesDiffer(fullSrcPath, fullDstPath);
    if (needsCopy) {
      log("verbose", `  Copying ${f.srcFile} to ${fullDstPath}`);
      copyFileSync(fullSrcPath, fullDstPath);
    }
    return needsCopy;
  }
};
function filesDiffer(aPath, bPath) {
  if (existsSync2(aPath) && existsSync2(bPath)) {
    const aSize = statSync(aPath).size;
    const bSize = statSync(bPath).size;
    if (aSize !== bSize) {
      return true;
    } else {
      const aBuf = readFileSync(aPath);
      const bBuf = readFileSync(bPath);
      return !aBuf.equals(bBuf);
    }
  } else {
    return true;
  }
}

// src/build/impl/gen-model.ts
import { copyFile, readdir, readFile, writeFile } from "fs/promises";
import { basename, dirname as dirname2, join as joinPath3 } from "path";
async function generateModel(context, plugins) {
  const config = context.config;
  if (config.modelFiles.length === 0) {
    log("info", "No model input files specified, skipping model generation steps");
    return;
  }
  log("info", "Generating model...");
  const t0 = performance.now();
  const prepDir = config.prepDir;
  const sdeCmdPath = config.sdeCmdPath;
  for (const plugin of plugins) {
    if (plugin.preProcessMdl) {
      await plugin.preProcessMdl(context);
    }
  }
  if (config.modelFiles.length === 1) {
    await preprocessMdl(context, sdeCmdPath, prepDir, config.modelFiles[0]);
  } else {
    await flattenMdls(context, sdeCmdPath, prepDir, config.modelFiles);
  }
  for (const plugin of plugins) {
    if (plugin.postProcessMdl) {
      const mdlPath = joinPath3(prepDir, "processed.mdl");
      let mdlContent = await readFile(mdlPath, "utf8");
      mdlContent = await plugin.postProcessMdl(context, mdlContent);
      await writeFile(mdlPath, mdlContent);
    }
  }
  for (const plugin of plugins) {
    if (plugin.preGenerateCode) {
      await plugin.preGenerateCode(context, config.genFormat);
    }
  }
  await generateCode(context, config.sdeDir, sdeCmdPath, prepDir);
  const generatedCodeFile = `processed.${config.genFormat}`;
  const generatedCodePath = joinPath3(prepDir, "build", generatedCodeFile);
  for (const plugin of plugins) {
    if (plugin.postGenerateCode) {
      let generatedCodeContent = await readFile(generatedCodePath, "utf8");
      generatedCodeContent = await plugin.postGenerateCode(context, config.genFormat, generatedCodeContent);
      await writeFile(generatedCodePath, generatedCodeContent);
    }
  }
  if (config.genFormat === "js") {
    const outputJsFile = "generated-model.js";
    const stagedOutputJsPath = context.prepareStagedFile("model", outputJsFile, prepDir, outputJsFile);
    await copyFile(generatedCodePath, stagedOutputJsPath);
  }
  if (config.outListingFile) {
    const srcListingJsonPath = joinPath3(prepDir, "build", "processed.json");
    const stagedDir = "model";
    const stagedFile = "listing.json";
    const dstDir = dirname2(config.outListingFile);
    const dstFile = basename(config.outListingFile);
    const stagedListingJsonPath = context.prepareStagedFile(stagedDir, stagedFile, dstDir, dstFile);
    await copyFile(srcListingJsonPath, stagedListingJsonPath);
  }
  const t1 = performance.now();
  const elapsed = ((t1 - t0) / 1e3).toFixed(1);
  log("info", `Done generating model (${elapsed}s)`);
}
async function preprocessMdl(context, sdeCmdPath, prepDir, modelFile) {
  log("verbose", "  Preprocessing mdl file");
  await copyFile(modelFile, joinPath3(prepDir, "processed.mdl"));
  const command = sdeCmdPath;
  const args = ["generate", "--preprocess", "processed.mdl"];
  const ppOutput = await context.spawnChild(prepDir, command, args, {
    // The default error message from `spawnChild` is not very informative, so the
    // following allows us to throw our own error
    ignoreError: true
  });
  if (ppOutput.exitCode !== 0) {
    throw new Error(`Failed to preprocess mdl file: 'sde generate' command failed (code=${ppOutput.exitCode})`);
  }
  await copyFile(joinPath3(prepDir, "build", "processed.mdl"), joinPath3(prepDir, "processed.mdl"));
}
async function flattenMdls(context, sdeCmdPath, prepDir, modelFiles) {
  log("verbose", "  Flattening and preprocessing mdl files");
  const command = sdeCmdPath;
  const args = [];
  args.push("flatten");
  args.push("processed.mdl");
  args.push("--inputs");
  for (const path of modelFiles) {
    args.push(path);
  }
  const output = await context.spawnChild(prepDir, command, args, {
    logOutput: false,
    captureOutput: true,
    ignoreError: true
  });
  let flattenErrors = false;
  for (const msg of output.stderrMessages) {
    if (msg.includes("ERROR")) {
      flattenErrors = true;
      break;
    }
  }
  if (flattenErrors) {
    log("error", "There were errors reported when flattening the model:");
    for (const msg of output.stderrMessages) {
      const lines = msg.split("\n");
      for (const line of lines) {
        log("error", `  ${line}`);
      }
    }
    throw new Error(`Failed to flatten mdl files: 'sde flatten' command failed (code=${output.exitCode})`);
  } else if (output.exitCode !== 0) {
    throw new Error(`Failed to flatten mdl files: 'sde flatten' command failed (code=${output.exitCode})`);
  }
  await copyFile(joinPath3(prepDir, "build", "processed.mdl"), joinPath3(prepDir, "processed.mdl"));
}
async function generateCode(context, sdeDir, sdeCmdPath, prepDir) {
  const genFormat = context.config.genFormat;
  const genFormatName = genFormat.toUpperCase();
  log("verbose", `  Generating ${genFormatName} code`);
  const command = sdeCmdPath;
  const outFormat = `--outformat=${genFormat}`;
  const genCmdArgs = ["generate", outFormat, "--list", "--spec", "spec.json", "processed"];
  const genCmdOutput = await context.spawnChild(prepDir, command, genCmdArgs, {
    // By default, ignore lines that start with "WARNING: Data for" since these are often harmless
    // TODO: Don't filter by default, but make it configurable
    // ignoredMessageFilter: 'WARNING: Data for'
    // The default error message from `spawnChild` is not very informative, so the
    // following allows us to throw our own error
    ignoreError: true
  });
  if (genCmdOutput.exitCode !== 0) {
    throw new Error(
      `Failed to generate ${genFormatName} code: 'sde generate' command failed (code=${genCmdOutput.exitCode})`
    );
  }
  if (genFormat === "c") {
    const buildDir = joinPath3(prepDir, "build");
    const sdeCDir = joinPath3(sdeDir, "src", "c");
    const files = await readdir(sdeCDir);
    const copyOps = [];
    for (const file of files) {
      if (file.endsWith(".c") || file.endsWith(".h")) {
        copyOps.push(copyFile(joinPath3(sdeCDir, file), joinPath3(buildDir, file)));
      }
    }
    await Promise.all(copyOps);
  }
}

// src/build/impl/hash-files.ts
import { join as joinPath4 } from "path";
import { hashElement } from "folder-hash";
import glob from "tiny-glob";
async function computeInputFilesHash(config) {
  const inputFiles = [];
  const specFile = joinPath4(config.prepDir, "spec.json");
  inputFiles.push(specFile);
  if (config.modelInputPaths && config.modelInputPaths.length > 0) {
    for (const globPath of config.modelInputPaths) {
      const paths = await glob(globPath, {
        cwd: config.rootDir,
        absolute: true,
        filesOnly: true
      });
      inputFiles.push(...paths);
    }
  } else {
    inputFiles.push(...config.modelFiles);
  }
  let hash = "";
  for (const inputFile of inputFiles) {
    const result = await hashElement(inputFile);
    hash += result.hash;
  }
  return hash;
}

// src/build/impl/build-once.ts
async function buildOnce(config, userConfig, plugins, options) {
  const stagedFiles = new StagedFiles(config.prepDir);
  const context = new BuildContext(config, stagedFiles, options.abortSignal);
  const modelHashPath = joinPath5(config.prepDir, "model-hash.txt");
  let succeeded = true;
  try {
    const userModelSpec = await userConfig.modelSpec(context);
    if (userModelSpec === void 0) {
      return err2(new Error("The model spec must be defined"));
    }
    const modelSpec = resolveModelSpec(userModelSpec);
    for (const plugin of plugins) {
      if (plugin.preGenerate) {
        await plugin.preGenerate(context, modelSpec);
      }
    }
    const specJson = {
      inputVarNames: modelSpec.inputVarNames,
      outputVarNames: modelSpec.outputVarNames,
      externalDatfiles: modelSpec.datFiles,
      bundleListing: modelSpec.bundleListing,
      customLookups: modelSpec.customLookups,
      customOutputs: modelSpec.customOutputs,
      ...modelSpec.options
    };
    const specPath = joinPath5(config.prepDir, "spec.json");
    await writeFile2(specPath, JSON.stringify(specJson, null, 2));
    let previousModelHash;
    if (existsSync3(modelHashPath)) {
      previousModelHash = readFileSync2(modelHashPath, "utf8");
    } else {
      previousModelHash = "NONE";
    }
    const inputFilesHash = await computeInputFilesHash(config);
    let needModelGen;
    if (options.forceModelGen === true) {
      needModelGen = true;
    } else {
      const hashMismatch = inputFilesHash !== previousModelHash;
      needModelGen = hashMismatch;
    }
    if (needModelGen) {
      await generateModel(context, plugins);
      writeFileSync3(modelHashPath, inputFilesHash);
    } else {
      log("info", "Skipping model code generation; already up-to-date");
    }
    for (const plugin of plugins) {
      if (plugin.postGenerate) {
        const pluginSucceeded = await plugin.postGenerate(context, modelSpec);
        if (!pluginSucceeded) {
          succeeded = false;
        }
      }
    }
    stagedFiles.copyChangedFiles();
    for (const plugin of plugins) {
      if (plugin.postBuild) {
        const pluginSucceeded = await plugin.postBuild(context, modelSpec);
        if (!pluginSucceeded) {
          succeeded = false;
        }
      }
    }
    if (config.mode === "development") {
      log("info", "Waiting for changes...\n");
      clearOverlay();
    }
  } catch (e) {
    if (e.message !== "ABORT") {
      writeFileSync3(modelHashPath, "");
      return err2(e);
    }
  }
  return ok2(succeeded);
}
function resolveModelSpec(modelSpec) {
  let inputVarNames;
  let inputSpecs;
  if (modelSpec.inputs.length > 0) {
    const item = modelSpec.inputs[0];
    if (typeof item === "string") {
      inputVarNames = modelSpec.inputs;
      inputSpecs = inputVarNames.map((varName) => {
        return {
          varName
        };
      });
    } else {
      inputSpecs = modelSpec.inputs;
      inputVarNames = inputSpecs.map((spec) => spec.varName);
    }
  } else {
    inputVarNames = [];
    inputSpecs = [];
  }
  let outputVarNames;
  let outputSpecs;
  if (modelSpec.outputs.length > 0) {
    const item = modelSpec.outputs[0];
    if (typeof item === "string") {
      outputVarNames = modelSpec.outputs;
      outputSpecs = outputVarNames.map((varName) => {
        return {
          varName
        };
      });
    } else {
      outputSpecs = modelSpec.outputs;
      outputVarNames = outputSpecs.map((spec) => spec.varName);
    }
  } else {
    outputVarNames = [];
    outputSpecs = [];
  }
  let customLookups;
  if (modelSpec.customLookups !== void 0) {
    customLookups = modelSpec.customLookups;
  } else {
    customLookups = false;
  }
  let customOutputs;
  if (modelSpec.customOutputs !== void 0) {
    customOutputs = modelSpec.customOutputs;
  } else {
    customOutputs = false;
  }
  return {
    inputVarNames,
    inputs: inputSpecs,
    outputVarNames,
    outputs: outputSpecs,
    datFiles: modelSpec.datFiles || [],
    bundleListing: modelSpec.bundleListing === true,
    customLookups,
    customOutputs,
    options: modelSpec.options
  };
}

// src/build/impl/watch.ts
import { basename as basename2 } from "path";
import chokidar from "chokidar";
var BuildState = class {
  constructor() {
    this.abortController = new AbortController();
  }
};
function watch(config, userConfig, plugins) {
  const delay = 150;
  const changedPaths = /* @__PURE__ */ new Set();
  let currentBuildState;
  function performBuild() {
    clearOverlay();
    for (const path of changedPaths) {
      log("info", `Input file ${basename2(path)} has been changed`);
    }
    changedPaths.clear();
    if (currentBuildState) {
      currentBuildState.abortController.abort();
      currentBuildState = void 0;
    }
    currentBuildState = new BuildState();
    const buildOptions = {
      abortSignal: currentBuildState.abortController.signal
    };
    buildOnce(config, userConfig, plugins, buildOptions).then((result) => {
      if (result.isErr()) {
        logError(result.error);
      }
    }).catch((e) => {
      logError(e);
    }).finally(() => {
      currentBuildState = void 0;
    });
  }
  function scheduleBuild(changedPath) {
    const schedule = changedPaths.size === 0;
    changedPaths.add(changedPath);
    if (schedule) {
      setTimeout(() => {
        performBuild();
      }, delay);
    }
  }
  let watchPaths;
  if (config.watchPaths && config.watchPaths.length > 0) {
    watchPaths = config.watchPaths;
  } else {
    watchPaths = config.modelFiles;
  }
  const watcher = chokidar.watch(watchPaths, {
    // Watch paths are resolved relative to the project root directory
    cwd: config.rootDir,
    // XXX: Include a delay, otherwise on macOS we sometimes get multiple
    // change events when the csv file is saved just once
    awaitWriteFinish: {
      stabilityThreshold: 200
    }
  });
  watcher.on("change", (path) => {
    scheduleBuild(path);
  });
}

// src/build/build.ts
async function build(mode, options) {
  const configResult = await loadConfig(mode, options.config, options.sdeDir, options.sdeCmdPath);
  if (configResult.isErr()) {
    return err3(configResult.error);
  }
  const { userConfig, resolvedConfig } = configResult.value;
  if (options.logLevels !== void 0) {
    setActiveLevels(options.logLevels);
  }
  const messagesPath = joinPath6(resolvedConfig.prepDir, "messages.html");
  const overlayEnabled2 = mode === "development";
  setOverlayFile(messagesPath, overlayEnabled2);
  try {
    const plugins = userConfig.plugins || [];
    for (const plugin of plugins) {
      if (plugin.init) {
        await plugin.init(resolvedConfig);
      }
    }
    if (mode === "development") {
      const buildResult = await buildOnce(resolvedConfig, userConfig, plugins, {});
      if (buildResult.isErr()) {
        return err3(buildResult.error);
      }
      for (const plugin of plugins) {
        if (plugin.watch) {
          await plugin.watch(resolvedConfig);
        }
      }
      watch(resolvedConfig, userConfig, plugins);
      return ok3({});
    } else {
      const buildResult = await buildOnce(resolvedConfig, userConfig, plugins, {});
      if (buildResult.isErr()) {
        return err3(buildResult.error);
      }
      const allPluginsSucceeded = buildResult.value;
      const exitCode = allPluginsSucceeded ? 0 : 2;
      return ok3({ exitCode });
    }
  } catch (e) {
    return err3(e);
  }
}
export {
  build
};
//# sourceMappingURL=index.js.map